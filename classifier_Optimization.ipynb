{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe958989-08cd-4ea5-8c52-8db17e3fb7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, yaml, h5py, random\n",
    "import gc\n",
    "import numpy as np\n",
    "import os, glob\n",
    "import time\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import *\n",
    "from dataset_loder import *\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import wandb\n",
    "import importlib\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c3ba3ad-30a6-4f47-ba3f-0cb9249d8181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "def set_random_seeds(random_seed=0):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "set_random_seeds(42)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Correct way to specify GPU index\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b26a148-75ec-4db7-8cf0-e87bb2ace2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_epoch= 0\n",
    "\n",
    "lr_init= 1e-3\n",
    "lr_factor= .1\n",
    "new_lr= 1e-3\n",
    "reslayers= [8,16,32,64]\n",
    "resblocks= 3\n",
    "channels= [0,1,2,3,4,5,6,7,8,9,10,11,12] \n",
    "\n",
    "loss_func= 'mse'\n",
    "scheduler_= 'cosine'\n",
    "optimizer_= 'Adam'\n",
    "patience= 2\n",
    "scheduler_mode= 'min'\n",
    "BATCH_SIZE= 128\n",
    "VAL_BATCH_SIZE= 128\n",
    "TEST_BATCH_SIZE= 128\n",
    "indices= [0,1,2,3,4,5,6,7,8,9,10,11,12] \n",
    "\n",
    "epochs= 2\n",
    "n_train= -1\n",
    "n_valid= -1\n",
    "n_test= 40\n",
    "\n",
    "m0_scale = 14\n",
    "mass_mean= 9.025205 \n",
    "mass_std= 5.1880417\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "random_seed=42\n",
    "w_iter_freq=50\n",
    "num_data_workers= 4\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "deb7aa0c-5065-494f-95c4-42cf0abca223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from /global/cfs/cdirs/m4392/bbbam/jupyter_notebook_new/classification/ResNet_classifier/13_ch_classifier_ResNet_mapA/MODELS/model_epoch30_auc0.9476.pkl\n",
      "Validation (1/85): Val loss:0.388102, acc:0.855000\n",
      "Validation (51/85): Val loss:0.383801, acc:0.844235\n",
      "30: Val loss:0.382681, acc71.868004\n",
      ">>>>>>>>>>>>>>>>>> Done for DYToTauTau_M-50_13TeV_valid.h5 >>>>>>>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/b/bbbam/.conda/envs/Pytorch_VEN/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1133: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation (1/709): Val loss:0.382357, acc:0.817000\n",
      "Validation (51/709): Val loss:0.358794, acc:0.832177\n",
      "Validation (101/709): Val loss:0.358927, acc:0.832832\n",
      "Validation (151/709): Val loss:0.358925, acc:0.833291\n",
      "Validation (201/709): Val loss:0.358191, acc:0.833478\n",
      "Validation (251/709): Val loss:0.357948, acc:0.833737\n",
      "Validation (301/709): Val loss:0.357960, acc:0.833581\n",
      "Validation (351/709): Val loss:0.357647, acc:0.833972\n",
      "Validation (401/709): Val loss:0.357959, acc:0.833830\n",
      "Validation (451/709): Val loss:0.357671, acc:0.834093\n",
      "Validation (501/709): Val loss:0.357916, acc:0.833994\n",
      "Validation (551/709): Val loss:0.358205, acc:0.833784\n",
      "Validation (601/709): Val loss:0.358072, acc:0.834025\n",
      "Validation (651/709): Val loss:0.357750, acc:0.834264\n",
      "Validation (701/709): Val loss:0.357538, acc:0.834298\n",
      "30: Val loss:0.357459, acc591.562839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/b/bbbam/.conda/envs/Pytorch_VEN/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>> Done for IMG_H_AATo4Tau_Hadronic_tauDR0p4_M3p7_signal_v2_2.h5 >>>>>>>>>>>>>\n",
      "Validation (1/521): Val loss:0.263100, acc:0.887000\n",
      "Validation (51/521): Val loss:0.297944, acc:0.865333\n",
      "Validation (101/521): Val loss:0.298160, acc:0.865178\n",
      "Validation (151/521): Val loss:0.298552, acc:0.864702\n",
      "Validation (201/521): Val loss:0.299789, acc:0.863761\n",
      "Validation (251/521): Val loss:0.299309, acc:0.863677\n",
      "Validation (301/521): Val loss:0.299532, acc:0.863488\n",
      "Validation (351/521): Val loss:0.300260, acc:0.863051\n",
      "Validation (401/521): Val loss:0.299952, acc:0.863105\n",
      "Validation (451/521): Val loss:0.299931, acc:0.863142\n",
      "Validation (501/521): Val loss:0.299875, acc:0.863066\n",
      "30: Val loss:0.299579, acc449.749909\n",
      ">>>>>>>>>>>>>>>>>> Done for IMG_H_AATo4Tau_Hadronic_tauDR0p4_M5_signal_v2_2.h5 >>>>>>>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/b/bbbam/.conda/envs/Pytorch_VEN/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation (1/85): Val loss:0.320898, acc:0.853000\n",
      "Validation (51/85): Val loss:0.374212, acc:0.828157\n",
      "30: Val loss:0.376644, acc70.335003\n",
      ">>>>>>>>>>>>>>>>>> Done for TTToHadronic_valid.h5 >>>>>>>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/b/bbbam/.conda/envs/Pytorch_VEN/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1133: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation (1/85): Val loss:0.391073, acc:0.838000\n",
      "Validation (51/85): Val loss:0.377137, acc:0.848549\n",
      "30: Val loss:0.375663, acc72.132004\n",
      ">>>>>>>>>>>>>>>>>> Done for GGH_TauTau_valid.h5 >>>>>>>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/b/bbbam/.conda/envs/Pytorch_VEN/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1133: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation (1/679): Val loss:0.339238, acc:0.857000\n",
      "Validation (51/679): Val loss:0.339915, acc:0.845059\n",
      "Validation (101/679): Val loss:0.338835, acc:0.844525\n",
      "Validation (151/679): Val loss:0.338592, acc:0.843947\n",
      "Validation (201/679): Val loss:0.338382, acc:0.844124\n",
      "Validation (251/679): Val loss:0.338723, acc:0.843582\n",
      "Validation (301/679): Val loss:0.339849, acc:0.842947\n",
      "Validation (351/679): Val loss:0.339828, acc:0.842969\n",
      "Validation (401/679): Val loss:0.339367, acc:0.843476\n",
      "Validation (451/679): Val loss:0.339670, acc:0.843100\n",
      "Validation (501/679): Val loss:0.340199, acc:0.842920\n",
      "Validation (551/679): Val loss:0.340367, acc:0.843004\n",
      "Validation (601/679): Val loss:0.340410, acc:0.842995\n",
      "Validation (651/679): Val loss:0.340519, acc:0.843068\n",
      "30: Val loss:0.340613, acc572.410694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/b/bbbam/.conda/envs/Pytorch_VEN/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1124: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>>>>>>>>>> Done for IMG_H_AATo4Tau_Hadronic_tauDR0p4_M4_signal_v2_2.h5 >>>>>>>>>>>>>\n",
      "Validation (1/85): Val loss:0.167179, acc:0.930000\n",
      "Validation (51/85): Val loss:0.143603, acc:0.934314\n",
      "30: Val loss:0.144922, acc79.379004\n",
      ">>>>>>>>>>>>>>>>>> Done for QCD_Pt-15to7000_valid.h5 >>>>>>>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/b/bbbam/.conda/envs/Pytorch_VEN/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1133: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation (1/85): Val loss:0.083031, acc:0.976000\n",
      "Validation (51/85): Val loss:0.103703, acc:0.960255\n",
      "30: Val loss:0.103204, acc81.656004\n",
      ">>>>>>>>>>>>>>>>>> Done for WJetsToLNu_valid.h5 >>>>>>>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/b/bbbam/.conda/envs/Pytorch_VEN/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:1133: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_epoch = 30\n",
    "epoch = load_epoch\n",
    "BATCH_SIZE=1000\n",
    "import torch_resnet_concat as networks\n",
    "\n",
    "out_dir =\"/global/cfs/cdirs/m4392/bbbam/jupyter_notebook_new/classification/ResNet_classifier\"\n",
    "model_dir ='13_ch_classifier_ResNet_mapA'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "resnet = networks.ResNet_mapA(in_channels=13, nblocks=3, fmaps=[8,16,32,64], alpha=1)\n",
    "resnet=resnet.to(device)\n",
    "load_model = glob.glob(f'{out_dir}/{model_dir}/MODELS/model_epoch{load_epoch}*')[0]#loading  model mannually\n",
    "print('Loading weights from %s'%load_model)\n",
    "checkpoint = torch.load(load_model, weights_only=False)\n",
    "resnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "input_datasets = ['DYToTauTau_M-50_13TeV_valid.h5', 'IMG_H_AATo4Tau_Hadronic_tauDR0p4_M3p7_signal_v2_2.h5', 'IMG_H_AATo4Tau_Hadronic_tauDR0p4_M5_signal_v2_2.h5',\n",
    "                 'TTToHadronic_valid.h5', 'GGH_TauTau_valid.h5', 'IMG_H_AATo4Tau_Hadronic_tauDR0p4_M4_signal_v2_2.h5', 'QCD_Pt-15to7000_valid.h5', 'WJetsToLNu_valid.h5']\n",
    "\n",
    "for input_dataset in input_datasets:\n",
    "    out_tag = input_dataset.split('.')[0]\n",
    "    # print(\"out_tag\", out_tag)\n",
    "    test_dir = f'/global/cfs/cdirs/m4392/bbbam/classifier_signal_background_Run2_valid_h5/{input_dataset}'\n",
    "    test_dset = ClassifierDataset(test_dir , selected_channels=indices, preload_size=32)\n",
    "    test_indices = list(range(len(test_dset)))\n",
    "    test_sampler = ChunkedSampler(test_indices, chunk_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dset, batch_size=BATCH_SIZE, sampler=test_sampler, pin_memory=True, num_workers=num_data_workers)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    loss_, acc_ = 0., 0.\n",
    "    y_pred_, y_true_ = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            X, y = data[0].to(device), data[1].to(device)\n",
    "            iphi, ieta = data[2].to(device), data[3].to(device)\n",
    "    \n",
    "            iphi = iphi/360.\n",
    "            ieta = ieta/140.\n",
    "            logits = resnet([X, iphi, ieta])\n",
    "            loss=  F.binary_cross_entropy_with_logits(logits, y)\n",
    "            loss_ += loss.item()\n",
    "            pred = logits.ge(0.).byte()\n",
    "            acc_ += pred.eq(y.byte()).float().mean().item()\n",
    "            y_pred_.append(torch.sigmoid(logits).detach().cpu().numpy())\n",
    "            y_true_.append(y.detach().cpu().numpy())\n",
    "    \n",
    "    \n",
    "            if i % 50  == 0:\n",
    "                \n",
    "    \n",
    "               print('Validation (%d/%d): Val loss:%f, acc:%f'%(i+1, len(test_loader), loss_/(i+1), acc_/(i+1) ))\n",
    "    \n",
    "    \n",
    "        y_pred_ = np.concatenate(y_pred_)\n",
    "        y_true_ = np.concatenate(y_true_)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        print('%d: Val loss:%f, acc%f'%(epoch, loss_/len(test_loader), np.mean(acc_)))\n",
    "    \n",
    "    \n",
    "        # fpr, tpr, _ = roc_curve(y_true_, y_pred_)\n",
    "        # roc_auc = auc(fpr, tpr)\n",
    "       \n",
    "        output_dict = {}\n",
    "        output_dict[\"y_true\"] = y_true_\n",
    "        output_dict[\"y_pred\"] = y_pred_\n",
    "        # output_dict[\"fpr\"] = fpr\n",
    "        # output_dict[\"tpr\"] = tpr\n",
    "    \n",
    "   \n",
    "        with open(f'{out_dir}/{model_dir}/{out_tag}.pkl', \"wb\") as outfile:\n",
    "            pickle.dump(output_dict, outfile, protocol=2) #protocol=2 for compatibility\n",
    "        print(f\">>>>>>>>>>>>>>>>>> Done for {input_dataset} >>>>>>>>>>>>>\")\n",
    "    \n",
    "    \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64c42e-fb29-44fa-ba64-b136441d79a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3e8b5-c07d-4f7b-a491-3135ab95e96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abcd16a-8a1d-45f0-9b6c-cd1b2b140ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb692d-8c33-46fa-8741-19d9a7060cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch_VEN",
   "language": "python",
   "name": "pytorch_ven"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
